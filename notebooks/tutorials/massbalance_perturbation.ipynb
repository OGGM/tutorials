{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass balance parameter perturbation experiments with OGGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we assume that you have read and run the [mass balance calibration tutorial](massbalance_calibration.ipynb). We know that it is a lot of new information to take in!\n",
    "\n",
    "In this notebook, we will:\n",
    "- re-iterate and discuss the important role that mass balance calibration plays in the projections\n",
    "- give you some tools to run parameter perturbation experiments (this will also illustrate useful aspects of the OGGM internals)\n",
    "- provide some keys about how to address the calibration process in your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import oggm\n",
    "from oggm import cfg, utils, workflow, tasks, graphics\n",
    "from oggm.core import massbalance\n",
    "from oggm.core.massbalance import mb_calibration_from_scalar_mb, mb_calibration_from_geodetic_mb, mb_calibration_from_wgms_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.initialize(logging_level='WARNING')\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='OGGM-calib-pertubation', reset=True)\n",
    "cfg.PARAMS['border'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from our two well known glaciers in the Austrian Alps, Kesselwandferner and Hintereisferner. But you can also choose any other other glacier, e.g. from [this list](https://github.com/OGGM/oggm-sample-data/blob/master/wgms/rgi_wgms_links_20220112.csv). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start from preprocessing level 5\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/'\n",
    "gdirs = workflow.init_glacier_directories(['RGI60-11.00787',  'RGI60-11.00897'], from_prepro_level=5, prepro_base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the mass balance parameters for the mass balance model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just downloaded the data. Let's have a look at the calibrated parameters for these glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick each glacier\n",
    "gdir_kwf = gdirs[0]\n",
    "gdir_hef = gdirs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdir_hef.read_json('mb_calib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdir_kwf.read_json('mb_calib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters are stored in a file called `mb_calib.json` in the glacier directory. This file is then read by the mass balance model when created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbmod = massbalance.MonthlyTIModel(gdir_hef)\n",
    "mbmod.calib_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if you want to mess around with these parameters, \"all you have to do\" is to overwrite this file somehow, or create a new one and ask the mass balance model to read it instead of the default one. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gdir_hef.read_json('mb_calib')\n",
    "params['melt_f'] = 7  # a new value\n",
    "gdir_hef.write_json(params, 'mb_calib', filesuffix='_perturbed')  # write a new file, with perturbed parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read it in with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbmod_perturbed = massbalance.MonthlyTIModel(gdir_hef, mb_params_filesuffix='_perturbed')\n",
    "mbmod_perturbed.calib_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, check what this means for the mass balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.linspace(2000, 3800, 80)\n",
    "mb_default = mbmod.get_annual_mb(h, year=1980) * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']\n",
    "mb_perturbed = mbmod_perturbed.get_annual_mb(h, year=1980) * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']\n",
    "plt.plot(mb_default, h);\n",
    "plt.plot(mb_perturbed, h);\n",
    "plt.xlabel('Mass balance (mm w.e)'); plt.ylabel('Elevation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. But how to feed this into the heavy OGGM pipeline? Many OGGM users will be more familiar with the `run_*` entity tasks. These tasks \"hide\" the process of creating the mass balance model and therefore make it look like we cant's change anything internally.\n",
    "\n",
    "We *could* have added a mechanism to pass the `mb_params_filesuffix` from, for example, `run_random_climate`, to the underlying mass balance model (similar to the \"climate_input_filesuffix\" mechanism). We may add this one day, but for now I'd like to use this opportunity to demonstrate another possible mechanism: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far so good: default run with the default mass balance\n",
    "tasks.run_random_climate(gdir_hef, y0=2000, nyears=100, seed=1, output_filesuffix='_default');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' create another \"mass balance model\" which is like the default one but with another default parameter\n",
    "from functools import partial\n",
    "PerturbedMassBalance = partial(massbalance.MonthlyTIModel, mb_params_filesuffix='_perturbed')\n",
    "\n",
    "# Pass it to the run task\n",
    "tasks.run_random_climate(gdir_hef, y0=2000, nyears=100, seed=1, mb_model_class=PerturbedMassBalance, output_filesuffix='_perturbed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial function allows to create a function that is created by fixing a certain number of arguments of another function. Here we create a new \"class\" which is the same as the default original one, but by setting one parameters to another value. This proves very useful here, since we are just tricking OGGM into using the new one!\n",
    "\n",
    "Let's check the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(gdir_hef.get_filepath('model_diagnostics', filesuffix='_default')) as ds:\n",
    "    ds_default = ds.load()\n",
    "with xr.open_dataset(gdir_hef.get_filepath('model_diagnostics', filesuffix='_perturbed')) as ds:\n",
    "    ds_perturbed = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_default.volume_m3.plot(label='Default');\n",
    "ds_perturbed.volume_m3.plot(label='Perturbed');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a big difference for \"just\" 2 units of melt factor more, from 5 to 7!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More structured parameters perturbation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so let's say we want to do this \"at scale\". We actually had such an assignment recently for the PROTECT SLR project. We were asked to do a number of perturbed simulations with parameters diverging from their default values, for example +1 temp_bias everywhere. But how to do this, knowing that each glacier has a different temp_bias? We can't simply set the bias to 1 everywhere (we need +=1).\n",
    "\n",
    "For this I wrote a \"task\", originally outside of OGGM but that is now (v1.6.4) part of the main codebase. Let's have a look at it:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "@entity_task(log, writes=['mb_calib'])\n",
    "def perturbate_mb_params(gdir, perturbation=None, reset_default=False, filesuffix=''):\n",
    "    \"\"\"Replaces pre-calibrated MB params with perturbed ones for this glacier.\n",
    "\n",
    "    It simply replaces the existing `mb_calib.json` file with an\n",
    "    updated one with perturbed parameters. The original ones\n",
    "    are stored in the file for re-use after perturbation.\n",
    "\n",
    "    Users can change the following 4 parameters:\n",
    "    - 'melt_f': unit [kg m-2 day-1 K-1], the melt factor\n",
    "    - 'prcp_fac': unit [-], the precipitation factor\n",
    "    - 'temp_bias': unit [K], the temperature correction applied to the timeseries\n",
    "    - 'bias': unit [mm we yr-1], *substracted* from the computed MB. Rarely used.\n",
    "\n",
    "    All parameter perturbations are additive, i.e. the value\n",
    "    provided by the user is added to the *precalibrated* value.\n",
    "    For example, `temp_bias=1` means that the temp_bias used by the\n",
    "    model will be the precalibrated one, plus 1 Kelvin.\n",
    "\n",
    "    The only exception is prpc_fac, which is multiplicative.\n",
    "    For example prcp_fac=1 will leave the precalibrated prcp_fac unchanged,\n",
    "    while 2 will double it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    perturbation : dict\n",
    "        the parameters to change and the associated value (see doc above)\n",
    "    reset_default : bool\n",
    "        reset the parameters to their original value. This might be\n",
    "        unnecessary if using the filesuffix mechanism.\n",
    "    filesuffix : str\n",
    "        write the modified parameters in a separate mb_calib.json file\n",
    "        with the filesuffix appended. This can then be read by the\n",
    "        MassBalanceModel for example instead of the default one.\n",
    "        Note that it's always the default, precalibrated params\n",
    "        file which is read to start with.\n",
    "    \"\"\"\n",
    "    df = gdir.read_json('mb_calib')\n",
    "\n",
    "    # Save original params if not there\n",
    "    if 'bias_orig' not in df:\n",
    "        for k in ['bias', 'melt_f', 'prcp_fac', 'temp_bias']:\n",
    "            df[k + '_orig'] = df[k]\n",
    "\n",
    "    if reset_default:\n",
    "        for k in ['bias', 'melt_f', 'prcp_fac', 'temp_bias']:\n",
    "            df[k] = df[k + '_orig']\n",
    "        gdir.write_json(df, 'mb_calib', filesuffix=filesuffix)\n",
    "        return df\n",
    "\n",
    "    for k, v in perturbation.items():\n",
    "        if k == 'prcp_fac':\n",
    "            df[k] = df[k + '_orig'] * v\n",
    "        elif k in ['bias', 'melt_f', 'temp_bias']:\n",
    "            df[k] = df[k + '_orig'] + v\n",
    "        else:\n",
    "            raise InvalidParamsError(f'Perturbation not valid: {k}')\n",
    "\n",
    "    gdir.write_json(df, 'mb_calib', filesuffix=filesuffix)\n",
    "    return df\n",
    "```\n",
    "\n",
    "It's a fairly easy piece of code isn't it? Let's apply it in a latin hypercube parameter set where we change all parameters in a structured way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "sampler = qmc.LatinHypercube(d=3)\n",
    "sample = sampler.random(n=30)\n",
    "\n",
    "def log_scale_value(value, low, high):\n",
    "    \"\"\"This is to sample multiplicative factors in log space to avoid assymetry (detail, but important).\"\"\"\n",
    "    return 2**((np.log2(high) - np.log2(low))*value + np.log2(low))\n",
    "\n",
    "sample[:,0] = 4*sample[:,0] - 2  # DDF factor (melt_f): apply change [-2, +2] mm/(°C day)\n",
    "sample[:,1] = 2*sample[:,1] - 1  # temperature bias (temp_bias): apply change [-1, +1] °C\n",
    "sample[:,2] = log_scale_value(sample[:,2], 0.5, 2)  # precipitation scaling factor (prcp_fac): apply scaling [0.5, 2] on log2\n",
    "\n",
    "params_df = pd.DataFrame(sample, columns=['melt_f', 'temp_bias', 'prcp_fac'])\n",
    "params_df.plot.scatter(x='temp_bias', y='prcp_fac');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.set_logging_config('CRITICAL')  # shut down log output (bad!)\n",
    "cfg.PARAMS['continue_on_error'] = True\n",
    "\n",
    "for exp in range(len(params_df)):\n",
    "    params = params_df.loc[exp]\n",
    "    # clim_params = {k: params[k] for k in ('temp_bias', 'prcp_fac', 'melt_f')}\n",
    "    exp = f'{exp:02d}'\n",
    "    workflow.execute_entity_task(tasks.perturbate_mb_params, gdirs, perturbation=params, filesuffix=f'_{exp}')\n",
    "\n",
    "    PerturbedMassBalance = partial(massbalance.MonthlyTIModel, mb_params_filesuffix=f'_{exp}')\n",
    "    \n",
    "    workflow.execute_entity_task(tasks.run_random_climate, gdirs,          \n",
    "                                 y0=2000,\n",
    "                                 nyears=100,\n",
    "                                 seed=1,\n",
    "                                 mb_model_class=PerturbedMassBalance,\n",
    "                                 output_filesuffix=f'_{exp}',  # recognize the run for later\n",
    "                                 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "for exp in range(len(params_df)):\n",
    "    try:\n",
    "        ds = utils.compile_run_output(gdirs, input_filesuffix=f'_{exp:02d}')\n",
    "        if np.any(ds.volume.isnull()):\n",
    "            continue\n",
    "        out_df[f'{exp:02d}'] = ds.volume.sum(dim='rgi_id').to_series()\n",
    "    except RuntimeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.plot(legend=False, color='k', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters perturbation experiments which match observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section above is nice, but works only for a problem setting where we don't ask the mass balance model to match observations. If we were to match obervations, things would be quite different! \n",
    "\n",
    "To do this, we could define a new task very much like the above, but this time realizing a calibration step before writing its solution down.\n",
    "\n",
    "This exercise is left to the reader ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "- Check out the [massbalance_global_params.ipynb](massbalance_global_params.ipynb) notebook\n",
    "- return to the [OGGM documentation](https://docs.oggm.org)\n",
    "- back to the [table of contents](../welcome.ipynb)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
