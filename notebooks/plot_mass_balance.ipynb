{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Plotting the OGGM surface mass-balance, the ELA and AAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "A few recipes to help you to plot and analyse the mass-balance computed by OGGM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import oggm\n",
    "from oggm import cfg, utils, workflow, tasks, graphics, global_tasks\n",
    "from oggm.core import massbalance, flowline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.initialize(logging_level='WARNING')\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='OGGM-ref-mb', reset=True)\n",
    "cfg.PARAMS['border'] = 80\n",
    "cfg.PARAMS['store_model_geometry'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Hintereisferner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (The second glacier here we will only use in the second part of this notebook.)\n",
    "gdirs = workflow.init_glacier_directories(['RGI60-11.00897', 'RGI60-11.00001'], from_prepro_level=3)\n",
    "gdir = gdirs[0]\n",
    "tasks.init_present_time_glacier(gdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## With static geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "That's by far the easiest - that is how we mostly test and develop mass-balance models ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The very easy way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the calibrated mass-balance model - the default is to use OGGM's \"PastMassBalanceModel\"\n",
    "mbmod = massbalance.MultipleFlowlineMassBalance(gdir)\n",
    "\n",
    "# Compute the specific MB for this glacier\n",
    "fls = gdir.read_pickle('model_flowlines')\n",
    "years = np.arange(1950, 2019)\n",
    "mb_ts = mbmod.get_specific_mb(fls=fls, year=years)\n",
    "\n",
    "plt.plot(years, mb_ts);\n",
    "plt.ylabel('Specific MB (mm w.e.)');\n",
    "plt.xlabel('Year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case (Hintereisferner), we can also plot the measured data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reference mass-balance from the WGMS\n",
    "ref_df = gdir.get_ref_mb_data()\n",
    "# Get OGGM MB at the same dates\n",
    "ref_df['OGGM'] = mbmod.get_specific_mb(fls=fls, year=ref_df.index.values)\n",
    "# Plot\n",
    "plt.plot(ref_df.index, ref_df.OGGM, label='OGGM');\n",
    "plt.plot(ref_df.index, ref_df.ANNUAL_BALANCE, label='WGMS');\n",
    "plt.ylabel('Specific MB (mm w.e.)'); plt.legend();\n",
    "plt.xlabel('Year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass-balance profiles on flowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by noting that I used the `MultipleFlowlineMassBalance` model here. This is what OGGM uses for its runs, because we allow different model parameters for different flowlines. In many cases we don't need this, but sometimes we do. Let's see if we have different temperature sensititivites for Hintereisferner or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flmod in mbmod.flowline_mb_models:\n",
    "    print(flmod.mu_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have the same model parameters for each flowline (that's frequently the case). To get the mass-balance as a function of height we have several possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the flowlines are:\n",
    "heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=2000)\n",
    "# units kg ice per second to mm w.e. per year:\n",
    "mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density'] \n",
    "\n",
    "# Plot\n",
    "plt.plot(mb, heights, '*', label='2000');\n",
    "\n",
    "# Another year:\n",
    "heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=2001)\n",
    "# units kg ice per second to mm w.e. per year:\n",
    "mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density'] \n",
    "# Plot\n",
    "plt.plot(mb, heights, '*', label='2001');\n",
    "plt.ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass-balance at any height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we can either \"pick\" one of the single flowline mass-balance models or use the multiple one (it's the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = np.arange(2500, 4000)\n",
    "# Method 1\n",
    "mbmod1 = mbmod.flowline_mb_models[0]\n",
    "mb = mbmod1.get_annual_mb(heights, year=2001) * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density'] \n",
    "# Method 2\n",
    "mb2 = mbmod.get_annual_mb(heights, year=2001, fl_id=0) * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density'] \n",
    "np.testing.assert_allclose(mb, mb2)\n",
    "# Plot\n",
    "plt.plot(mb, heights, label='2001');\n",
    "plt.ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But again, for certain glaciers the mass-balance might change from one flowline to another!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass-balance during a transient run + bonus info (timestamps in OGGM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific (glacier-wide) MB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing, we only store the glacier volume, which is roughly equivalent to the mass-balance (up to numerical accuracy in the dynamical model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)\n",
    "tasks.run_from_climate_data(gdir, ye=2020);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))\n",
    "ds_diag.volume_m3.plot(); plt.title('Volume evolution of Hintereisferner');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: timestamps in OGGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a bit of a headache, so let's spend some time explaining this. OGGM was developed to follow the traditional \"hydrological year\" convention. So in the OGGM output files (and in the model internals), we use the same convention (history will tell if it was a good idea, I sometimes [regret it](https://github.com/OGGM/oggm/issues/1020)).\n",
    "\n",
    "We use what we call a \"floating year\" time stamp, which can be converted to real dates easily in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.utils import floatyear_to_date, hydrodate_to_calendardate\n",
    "print('Hydro dates')\n",
    "print(floatyear_to_date(2003.0))\n",
    "print(floatyear_to_date(2003.99))\n",
    "print('Calendar dates')\n",
    "print(hydrodate_to_calendardate(*floatyear_to_date(2003.0), start_month=10))\n",
    "print(hydrodate_to_calendardate(*floatyear_to_date(2003.99), start_month=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp used in the OGGM output files uses the same convention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_diag.time.values[0], ds_diag.calendar_year.values[0], ds_diag.calendar_month.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the simulation started in year 2004.0 (as of the OGGM update from 19.05.2020), which corresponds to the real date October 2003. This is in accordance with the RGI inventory date (probably based on satellite imagery taken in the summer 2003):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdir.rgi_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the simulation ends at the last possible date for which we have climate data for (i.e. the simulation stops at the end of September 2019, which translates to the beginning of hydrological year 2020):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_diag.time.values[-1], ds_diag.calendar_year.values[-1], ds_diag.calendar_month.values[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, you have to be careful about how you interpret these data or report them to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific MB from volume change time series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the specific MB from the delta volume divided by the glacier area, and compare it to observations and to the mass-balance computed with a fixed geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific MB over time (i.e. with changing geometry feedbacks)\n",
    "smb = (ds_diag.volume_m3.values[1:] - ds_diag.volume_m3.values[:-1]) / ds_diag.area_m2.values[1:]\n",
    "smb = smb * cfg.PARAMS['ice_density']  # in mm\n",
    "plt.plot(ds_diag.time[:-1], smb, label='OGGM (dynamics)'); \n",
    "# The SMB from WGMS and fixed geometry we already have\n",
    "plt.plot(ref_df.loc[2004:].index, ref_df.loc[2004:].OGGM, label='OGGM (fixed geom)');\n",
    "plt.plot(ref_df.loc[2004:].index, ref_df.loc[2004:].ANNUAL_BALANCE, label='WGMS');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few comments:\n",
    "- the systematic difference between WGMS and OGGM is due to the calibration of the model, which is done with fixed geometry (the bias is zero over the entire calibration period but changes sign over the 50 year period, see plot above)\n",
    "- the difference between OGGM dynamics and fixed geometry (so small that they are barely visible for this short time period) is due to:\n",
    "    - the changes in geometry during the simulation time (i.e. this difference grows with time)\n",
    "    - melt at the tongue which might be larger than the glacier thickness is not accounted for in the fixed geometry data (these are assumed to be small)\n",
    "    - numerical differences in the dynamical model (these are assumed to be small as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### MB profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time of writing, we do not store the mass-balance profiles during a transient run, although we could (and [should](https://github.com/OGGM/oggm/issues/1022)). To get the profiles with a dynamically changing geometry, there is no other way than either get the mass-balance during the simulation, or to fetch the model output and re-compute the mass-balance retroactively. \n",
    "\n",
    "**Note: the MB profiles themselves of course are not really affected by the changing geometry - what changes from one year to another is the altitude at which the model will compute the MB.** In other terms, if you are interested in the mass-balance profiles you are better of to use the fixed geometries approaches explained at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrospective MB from model output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads the model output file and makes it look like an OGGM flowline model\n",
    "dyn_mod = flowline.FileModel(gdir.get_filepath('model_geometry'))\n",
    "# Get the calibrated mass-balance model\n",
    "mbmod = massbalance.MultipleFlowlineMassBalance(gdir)\n",
    "# We can loop over the years and read the flowlines for each year\n",
    "for year in range(2004, 2017):\n",
    "    dyn_mod.run_until(year)\n",
    "    # Compute the SMB from the mass balance model and the flowlines heights at each year\n",
    "    h = []\n",
    "    smb = []\n",
    "    for fl_id, fl in enumerate(dyn_mod.fls):\n",
    "        h = np.append(h, fl.surface_h)\n",
    "        mb = mbmod.get_annual_mb(fl.surface_h, year=year, fl_id=fl_id) \n",
    "        smb = np.append(smb, mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density'] )\n",
    "    plt.plot(smb, h, '.', label=year)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the MB during the simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - also based on the new outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrium Line Altitude \n",
    "\n",
    "The second part of this notebook shows how you can compute the Equilbrium Line Altitude (ELA, the altitude at which the MB is equal to 0) with OGGM.\n",
    "\n",
    "As the ELA in OGGM only depends on the [mass balance model](https://docs.oggm.org/en/stable/mass-balance.html) itself (not on glacier geometry), there is no need to do a full model run to collect these values. This is also the reason why the ELA is no longer a part of the model run output, but is instead  a diagnostic variable that can be computed separately since OGGM v1.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and compile the ELA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tasks.compile_ela(gdirs, ys=2000, ye=2019);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per default, the file will be stored in the working directory and named `ELA.hdf` (you can choose to save the data in a `csv` file instead by setting the `csv` keyword to `True`). The location where the file is saved can be changed by specifying the `path` keyword.\n",
    "\n",
    "Let's read the file and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "ela_df = pd.read_hdf(os.path.join(cfg.PATHS['working_dir'], 'ELA.hdf'))\n",
    "\n",
    "# Plot it\n",
    "ela_df.plot();\n",
    "plt.xlabel('year'); plt.ylabel('ELA [m]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at many glaciers it might be useful to also plot the mean or average of the data. Let's plot the mean ELA and the glacier area weighted ELA average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [gd.rgi_area_km2 for gd in gdirs]\n",
    "\n",
    "avg = ela_df.mean(axis=1).to_frame(name='mean')\n",
    "avg['weighted average'] = np.average(ela_df, axis=1, weights=areas)\n",
    "\n",
    "avg.plot();\n",
    "plt.xlabel('year'); plt.ylabel('ELA [m]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would to ELA look like if the climate is 1° warmer? Lets have a look at one of the glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tasks.compile_ela(gdirs, ys=2000, ye=2019, temperature_bias=1, filesuffix='_t1')\n",
    "ela_df_t1 = pd.read_hdf(os.path.join(cfg.PATHS['working_dir'], 'ELA_t1.hdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ela_df.mean(axis=1), label='default climate')\n",
    "plt.plot(ela_df_t1.mean(axis=1), label=('default climate +1℃'))\n",
    "plt.xlabel('year CE'); plt.ylabel('ELA [m]'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `precipitation_factor` keyword, you can change the precipitation. Feel free to try that by yourself!\n",
    "\n",
    "Lets look at a longer timeseries, for one glacier only: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tasks.compile_ela(gdirs[0], ys=1902, ye=2019, filesuffix='_1901_2019', csv=True)\n",
    "ela_df_long = pd.read_csv(os.path.join(cfg.PATHS['working_dir'], 'ELA_1901_2019.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ELA can have a high year-to-year variability. Therefore we plot in addition to the regular ELA timeseries, the 5-year moving average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ela_df_long.plot();\n",
    "ela_df_long.rolling(5).mean().plot(ax=ax, lw=2, color='k', label='')\n",
    "plt.xlabel('year CE'); plt.ylabel('ELA [m]'); ax.legend([\"Annual\", \"5-yr average\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you're only intrested in specific years there is an option to just compute the ELA in those years. There is actually no need to save this data. Therefore we now just compute the ELA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs = [2000, 1950, 1980, 1960]\n",
    "ela_yrs = massbalance.compute_ela(gdirs[0], years=yrs)\n",
    "ela_yrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See in this case you can use any year as long as you have climate available for that year. However for plotting purposes it might be worth to sort the data, otherwise the following happens ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ela_yrs.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ela_yrs.sort_index(ascending=True).plot();\n",
    "plt.xlabel('year CE'); plt.ylabel('ELA [m]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now we have addressed most of the keyword agruments of the compile_ela and compute_ela functions. To use different climate than the default climate, you can make use of the `climate_filename` and `climate_input_filesuffix` keywords. In case you're not familiar with those yet, please check out the [run_with_gcm](run_with_gcm.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulation Area Ratio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the ELA, the Accumulation Area Ratio (AAR) is a diagostic variable. The AAR is currently not an output \n",
    "variable in OGGM, but it can easily be computed. It is even a part of the [glacier simulator](https://bokeh.oggm.org/simulator/app) and its [documentation](https://edu.oggm.org/en/latest/simulator.html#aar-accumulation-area-ratio). Below we give an example of how it can be computed after a model run. From the ELA \n",
    "computation, we already know the height where the mass balance is equal to zero. Now we need to compute the area \n",
    "of the glacier that is located above that line. Lets start with a static glacier with multiple flowlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first search the points along the flowlines that are above the ELA in a given year. Lets start with ELA in 2010\n",
    "and use again Hintereisferner. Here we check if the ELA lays below the flowline and if that is not the case which \n",
    "point along the flowline is the first below the ELA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELA_2010 = ela_df['RGI60-11.00897'][2010] \n",
    "\n",
    "p_ELA = np.empty(len(fls)) \n",
    "for fn in np.arange(len(fls)):\n",
    "    MB_check = fls[fn].surface_h < ELA_2010 \n",
    "    if MB_check[-1] == False:\n",
    "        p_ELA[fn] = len(fls[fn].surface_h)\n",
    "    else:\n",
    "        p_ELA[fn] = np.where(MB_check)[0][0] \n",
    "p_ELA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these points we can make a quick estimate of the AAR, by adding up the area above these points allong the \n",
    "flowline and diving by the total glacier area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC = np.empty(len(fls))\n",
    "\n",
    "for fn in np.arange(len(fls)):\n",
    "    if p_ELA[fn] == 0:\n",
    "        AC[fn] = 0\n",
    "    else:\n",
    "        AC[fn] = fls[fn].bin_area_m2[0:int(p_ELA[fn])].sum()\n",
    "    \n",
    "AAR_estimate = AC.sum()/gdir.rgi_area_m2\n",
    "AAR_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have looked at the static case we can continue with looking at dynamic glaciers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_area = np.empty(len(fls)) # initialize the arrays we need later on.\n",
    "total_area = np.empty(len(fls))\n",
    "AAR = np.empty(10)\n",
    "\n",
    "for kt in np.arange(2005,2015): # loop over the years of intrest\n",
    "    for fn in np.arange(len(fls)): # loop over the flowlines\n",
    "        geometry = xr.open_dataset(gdir.get_filepath('model_geometry'), group='fl_' + str(fn))\n",
    "        surface_h = (geometry.loc[dict(time=kt)].ts_section[:] / geometry.loc[dict(time=kt)].ts_width_m[:]) \\\n",
    "                                    + geometry.bed_h # calculate the surface heigth of the glacier\n",
    "        # select points the points in the accumulation zone and compute their area.\n",
    "        accumulation_area[fn] = np.sum(np.where(surface_h > ela_df['RGI60-11.00897'][kt],\n",
    "                                    geometry.loc[dict(time=kt)].ts_width_m[:], 0) \n",
    "                                    * geometry.dx * geometry.map_dx)\n",
    "        # compute the total area along the flowline\n",
    "        total_area[fn] = np.sum(geometry.loc[dict(time=kt)].ts_width_m[:] * geometry.dx * geometry.map_dx)\n",
    "    # compute the AAR in a given year\n",
    "    AAR[int(kt-2005)] = (np.sum(accumulation_area)/np.sum(total_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that this is just an example for computing the AAR. For a different glacier experiment you might need\n",
    "to adjust the code. e.g. if the glacier flowlines would have different temperature sensitivities, you need to take\n",
    "that in to consideration.  \n",
    "\n",
    "Here we plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(2005,2015), AAR, label='AAR from dynamic run')\n",
    "plt.scatter(2010, AAR_estimate, label='AAR example from static glacier')\n",
    "plt.xlim([2005,2014])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('year CE')\n",
    "plt.ylabel('AAR')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the plot that the difference between the AAR calculated from the dynamic glacier and the one of the \n",
    "static glacier is very similar. Over time you can expect that this difference becomes larger. Feel free to play \n",
    "around with that. \n",
    "\n",
    "Here we computed the AAR from the \"model perspective\", where the glacier is located in bins. You can however also \n",
    "choose to do some interpolation between the grid point above and below the ELA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "- return to the [OGGM documentation](https://docs.oggm.org)\n",
    "- back to the [table of contents](welcome.ipynb)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
