{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest gridded products such as ice velocity into OGGM (and compare them with the model output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our OGGM experiments we often want to compare the model output to other gridded observations or maybe we want to use additional data sets that are not currently in the [OGGM shop](https://docs.oggm.org/en/stable/input-data.html) to calibrate parameters in the model (e.g. Glen A creep parameter, sliding parameter or the calving constant of proportionality). If you are looking on ways or ideas on how to do this, you are in the right tutorial!\n",
    "\n",
    "In OGGM, a local map projection is defined for each glacier entity in the RGI inventory following the methods described in [Maussion and others (2019)](https://gmd.copernicus.org/articles/12/909/2019/). The model uses a Transverse Mercator projection centred on the glacier. A lot of data sets, especially those from Polar regions can have a different projections and if we are not careful, we would be making mistakes when we compare them with our model output or when we use such data sets to constrain our model experiments.\n",
    "\n",
    "> **NOTE**: This code needs [latest OGGM version](https://docs.oggm.org/en/stable/whats-new.html#version-history) to run.\n",
    "\n",
    "First lets import the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import salem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm import cfg, utils, workflow, tasks, graphics\n",
    "cfg.initialize(logging_level='WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='OGGM-shop-on-Flowlines', reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets define the glaciers for the run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_ids = ['RGI60-14.06794']  # Baltoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RGI version to use\n",
    "# Size of the map around the glacier.\n",
    "prepro_border = 80\n",
    "# Degree of processing level. This is OGGM specific and for the shop 1 is the one you want\n",
    "from_prepro_level = 3\n",
    "# URL of the preprocessed gdirs\n",
    "# we use elevation bands flowlines here\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.4/L3-L5_files/CRU/elev_bands/qc3/pcp2.5/no_match/'\n",
    "\n",
    "gdirs = workflow.init_glacier_directories(rgi_ids,\n",
    "                                          from_prepro_level=from_prepro_level,\n",
    "                                          prepro_base_url=base_url,\n",
    "                                          prepro_border=prepro_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdir = gdirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics.plot_googlemap(gdir, figsize=(8, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `gridded_data` file in the glacier directory \n",
    "\n",
    "A lot of the data that the model use and produce for a glacier is stored under [the glaciers directories](https://oggm.org/tutorials/stable/notebooks/getting_started.html#glacier-directories) in a NetCDF file called `gridded_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = gdir.get_filepath('gridded_data')\n",
    "fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(fpath) as ds:\n",
    "    ds = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=salem.get_cmap('topo')\n",
    "ds.topo.plot(figsize=(7, 4), cmap=cmap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.glacier_mask.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data from OGGM-Shop: bed topography data\n",
    "\n",
    "Additionally to the data produced by the model, the [OGGM-Shop](https://docs.oggm.org/en/stable/input-data.html) counts with routines that will automatically download and reproject other useful data sets into the glacier projection (For more information also check out this [notebook](https://oggm.org/tutorials/stable/notebooks/oggm_shop.html)). This data will be stored under the file described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OGGM can now download data from the [Farinotti et al., (2019) consensus estimate](https://www.nature.com/articles/s41561-019-0300-3) and reproject it to the glacier directories map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.shop import bedtopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.execute_entity_task(bedtopo.add_consensus_thickness, gdirs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(gdir.get_filepath('gridded_data')) as ds:\n",
    "    ds = ds.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the cell below might take a while... be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the salem map background, make countries in grey\n",
    "smap = ds.salem.get_map(countries=False)\n",
    "smap.set_shapefile(gdir.read_shapefile('outlines'))\n",
    "smap.set_topography(ds.topo.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "smap.set_data(ds.consensus_ice_thickness)\n",
    "smap.set_cmap('Blues')\n",
    "smap.plot(ax=ax)\n",
    "smap.append_colorbar(ax=ax, label='ice thickness (m)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OGGM-Shop: ITS-live "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example on how to extract velocity fields from the [ITS_live](https://its-live.jpl.nasa.gov/) Regional Glacier and Ice Sheet Surface Velocities Mosaic ([Gardner, A. et al 2019](http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/documentation/ITS_LIVE-Regional-Glacier-and-Ice-Sheet-Surface-Velocities.pdf)) at 120 m resolution and reproject this data to the OGGM-glacier grid. This only works where ITS-live data is available! (**not in the Alps**).\n",
    "\n",
    "\n",
    "The data source used is https://its-live.jpl.nasa.gov/#data. \n",
    "\n",
    "Currently the only data downloaded is the 120m composite for both (u, v) and their uncertainty. The composite is computed from the 1985 to 2018 average. If you want more velocity products, feel free to open a new topic on the OGGM issue tracker!\n",
    "\n",
    "> this will download severals large dataset (2~800MB) **depending on your connection might take a bit** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.shop import its_live\n",
    "workflow.execute_entity_task(its_live.velocity_to_gdir, gdirs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the entity task [its_live.velocity_to_gdir()](https://github.com/OGGM/oggm/blob/master/oggm/shop/its_live.py#L185) OGGM downloads and reprojects the ITS_live files to a given glacier map. \n",
    "\n",
    "The velocity components (**vx**, **vy**) are added to the `gridded_data` nc file.\n",
    "\n",
    "According to the [ITS_LIVE documentation](http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/documentation/ITS_LIVE-Regional-Glacier-and-Ice-Sheet-Surface-Velocities.pdf) velocities are given in ground units (i.e. absolute velocities). We then use bilinear interpolation to reproject the velocities to the local glacier map by re-projecting the vector distances (For more details feel free to checl out the [code](https://github.com/OGGM/oggm/blob/master/oggm/shop/its_live.py#L78)).\n",
    "\n",
    "By specifying `add_error=True` on `its_live.velocity_to_gdir(gdir, add_error=True)`, we also reproject and scale the error for each component (**evx**, **evy**).\n",
    "\n",
    "Now we can read in all the gridded data that comes with OGGM, including the ITS_Live velocity components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(gdir.get_filepath('gridded_data')) as ds:\n",
    "    ds = ds.load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the salem map background, make countries in grey\n",
    "smap = ds.salem.get_map(countries=False)\n",
    "smap.set_shapefile(gdir.read_shapefile('outlines'))\n",
    "smap.set_topography(ds.topo.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the velocity data\n",
    "u = ds.obs_icevel_x.where(ds.glacier_mask == 1)\n",
    "v = ds.obs_icevel_y.where(ds.glacier_mask == 1)\n",
    "ws = (u**2 + v**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ds.glacier_mask == 1` command will remove the data outside of the glacier outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the axes ready\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Quiver only every 3rd grid point\n",
    "us = u[1::5, 1::5]\n",
    "vs = v[1::5, 1::5]\n",
    "\n",
    "smap.set_data(ws)\n",
    "smap.set_cmap('Blues')\n",
    "smap.plot(ax=ax)\n",
    "smap.append_colorbar(ax=ax, label = 'ice velocity (m yr$^{-1}$)')\n",
    "\n",
    "# transform their coordinates to the map reference system and plot the arrows\n",
    "xx, yy = smap.grid.transform(us.x.values, us.y.values, crs=gdir.grid.proj)\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "qu = ax.quiver(xx, yy, us.values, vs.values)\n",
    "qk = ax.quiverkey(qu, 0.82, 0.97, 100, '100 m yr$^{-1}$',\n",
    "                   labelpos='E', coordinates='axes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin the data in `gridded_data` into OGGM elevation bands\n",
    "\n",
    "Now that we have added new data to the `gridded_data` file, we can bin the data sets into the same elevation bands as OGGM by recomputing the elevation bands flowlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.elevation_band_flowline(gdir,\n",
    "                              bin_variables=['consensus_ice_thickness', 'obs_icevel_x', 'obs_icevel_y'],\n",
    "                              preserve_totals=[True, False, False]  # I\"m actually not sure if preserving totals is meaningful with velocities - likely not\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created a csv in the glacier directory folder with the data binned to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(gdir.get_filepath('elevation_band_flowline'), index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['obs_velocity'] = (df['obs_icevel_x']**2 + df['obs_icevel_y']**2)**0.5\n",
    "df['bed_h'] = df['mean_elevation'] - df['consensus_ice_thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['mean_elevation', 'bed_h', 'obs_velocity']].plot(figsize=(10, 4), secondary_y='obs_velocity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The problem with this file is that it does not have a regular spacing**. The numerical model needs regular spacing, which is why OGGM does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes the csv file and prepares new 'inversion_flowlines.pkl' and created a new csv file with regular spacing\n",
    "tasks.fixed_dx_elevation_band_flowline(gdir,\n",
    "                                       bin_variables=['consensus_ice_thickness', 'obs_icevel_x', 'obs_icevel_y'],\n",
    "                                       preserve_totals=[True, False, False]\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular = pd.read_csv(gdir.get_filepath('elevation_band_flowline', filesuffix='_fixed_dx'), index_col=0)\n",
    "df_regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other variables have disappeared for saving space, but I think it would be nicer to have them here as well. We can grab them from the inversion flowlines (this could be better handled in OGGM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = gdir.read_pickle('inversion_flowlines')[0]\n",
    "df_regular['mean_elevation'] = fl.surface_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular['obs_velocity'] = (df_regular['obs_icevel_x']**2 + df_regular['obs_icevel_y']**2)**0.5\n",
    "df_regular['consensus_bed_h'] = df_regular['mean_elevation'] - df_regular['consensus_ice_thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular[['mean_elevation', 'consensus_bed_h', 'obs_velocity']].plot(figsize=(10, 4), secondary_y='obs_velocity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so more or less the same but this time on a regular grid. Note that these now have the same length as the OGGM inversion flowlines, i.e. one can do stuff such as comparing what OGGM has done for the inversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = gdir.read_pickle('inversion_output')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular['OGGM_bed'] = df_regular['mean_elevation'] - inv['thick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular[['mean_elevation', 'consensus_bed_h', 'OGGM_bed']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare velocities: at inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OGGM already inverted the ice thickness based on some optimisation such as matching the regional totals. Which parameters did we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gdir.get_diagnostics()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK set them so that we are consistent\n",
    "cfg.PARAMS['inversion_glen_a'] = d['inversion_glen_a']\n",
    "cfg.PARAMS['inversion_fs'] = d['inversion_fs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we overwrote the inversion flowlines we have to do stuff again\n",
    "utils.apply_test_ref_tstars()\n",
    "tasks.local_t_star(gdir)\n",
    "tasks.mu_star_calibration(gdir)\n",
    "tasks.prepare_for_inversion(gdir, add_debug_var=True)\n",
    "tasks.mass_conservation_inversion(gdir)\n",
    "tasks.compute_velocities(gdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = gdir.read_pickle('inversion_output')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular['OGGM_inversion_velocity'] = inv['u_surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular[['obs_velocity', 'OGGM_inversion_velocity']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocities during the run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversion velocities are for a glacier at equilibrium - this is not always meaningful. Lets do a run and store the velocities with time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.PARAMS['store_fl_diagnostics'] = True\n",
    "\n",
    "# if you start to look into velocities, you will see that OGGM is quite large \n",
    "# regarding numerical stabilities - here is a better default (yet not perfect)\n",
    "cfg.PARAMS['cfl_number'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.run_from_climate_data(gdir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(gdir.get_filepath('model_diagnostics')) as ds_diag:\n",
    "    ds_diag = ds_diag.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_diag.volume_m3.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(gdir.get_filepath('fl_diagnostics'), group='fl_0') as ds_fl:\n",
    "    ds_fl = ds_fl.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fl.sel(time=[2003, 2010, 2020]).ice_velocity_myr.plot(hue='time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OGGM model flowlines also have the downstream lines\n",
    "df_regular['OGGM_velocity_run_begin'] = ds_fl.sel(time=2003).ice_velocity_myr.data[:len(df_regular)]\n",
    "df_regular['OGGM_velocity_run_end'] = ds_fl.sel(time=2020).ice_velocity_myr.data[:len(df_regular)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular[['obs_velocity', 'OGGM_inversion_velocity', 'OGGM_velocity_run_begin', 'OGGM_velocity_run_end']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "papermill": {
   "duration": 78.878142,
   "end_time": "2019-05-02T12:30:59.784271",
   "environment_variables": {},
   "exception": null,
   "input_path": "dem_comparison.ipynb",
   "output_path": "out-param.ipynb",
   "parameters": {
    "rgi_id": "RGI60-03.02489"
   },
   "start_time": "2019-05-02T12:29:40.906129",
   "version": "1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
