{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Display glacier area and thickness changes on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from oggm import cfg\n",
    "from oggm import tasks, utils, workflow, graphics, DEFAULT_BASE_URL\n",
    "import salem\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This notebook proposes a method for redistributing glacier ice that has been simulated along the flowline after a glacier retreat simulation. Extrapolating the glacier ice onto a map involves certain assumptions and trade-offs. Depending on the purpose, different choices may be preferred. For example, higher resolution may be desired for visualization compared to using the output for a hydrological model. It is possible to add different options to the final function to allow users to select the option that best suits their needs.\n",
    "\n",
    "This notebook demonstrates the redistribution process using a single glacier. Its purpose is to initiate further discussion before incorporating it into the main OGGM code base (currently, it is in the sandbox)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Pick a glacier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize OGGM and set up the default run parameters\n",
    "cfg.initialize(logging_level='WARNING')\n",
    "\n",
    "# Local working directory (where OGGM will write its output)\n",
    "# WORKING_DIR = utils.gettempdir('OGGM_distr4')\n",
    "cfg.PATHS['working_dir'] = utils.get_temp_dir('OGGM_distributed', reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgi_ids = ['RGI60-11.01450',  # Aletsch\n",
    "           'RGI60-11.01478']  # Fieschergletscher\n",
    "gdirs = workflow.init_glacier_directories(rgi_ids, prepro_base_url=DEFAULT_BASE_URL, from_prepro_level=4, prepro_border=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment: a random warming simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here we use a random climate, but you can use any GCM, as long as glaciers are getting smaller, not bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do a random run with a bit of warming\n",
    "workflow.execute_entity_task(\n",
    "    tasks.run_random_climate,\n",
    "    gdirs,\n",
    "    ys=2020, ye=2100,  # Although the simulation is idealised, lets use real dates for the animation\n",
    "    y0=2009, halfsize=10,  # Random climate of 1999-2019\n",
    "    seed=1,  # Random number generator seed \n",
    "    temperature_bias=1.5,  # additional warming - change for other scenarios\n",
    "    store_fl_diagnostics=True,  # important! This will be needed for the redistribution\n",
    "    init_model_filesuffix='_spinup_historical',  # start from the spinup run\n",
    "    output_filesuffix='_random_s1',  # optional - here I just want to make things explicit as to which run we are using afterwards\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Redistribute: preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The required tasks can be found in the `distribute_2d` module of the sandbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from oggm.sandbox import distribute_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is to add a new topography to the file (smoothed differently)\n",
    "workflow.execute_entity_task(distribute_2d.add_smoothed_glacier_topo, gdirs)\n",
    "# This is to get the bed map at the start of the simulation\n",
    "workflow.execute_entity_task(tasks.distribute_thickness_per_altitude, gdirs)\n",
    "# This is to prepare the glacier directory for the interpolation (needs to be done only once)\n",
    "workflow.execute_entity_task(distribute_2d.assign_points_to_band, gdirs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Let's have a look at what we just did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdir = gdirs[0]  # here for Aletsch\n",
    "#gdir = gdirs[1]  # uncomment for Fieschergletscher\n",
    "\n",
    "with xr.open_dataset(gdir.get_filepath('gridded_data')) as ds:\n",
    "    ds = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inititial glacier thickness\n",
    "f, ax = plt.subplots()\n",
    "ds.distributed_thickness.plot(ax=ax);\n",
    "ax.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which points belongs to which band, and then within one band which are the first to melt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ds.band_index.plot.contourf(ax=ax1);\n",
    "ds.rank_per_band.plot(ax=ax2);\n",
    "ax1.axis('equal'); ax2.axis('equal'); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Redistribute simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The tasks above need to be run only once. The next one however should be done for each simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = workflow.execute_entity_task(\n",
    "    distribute_2d.distribute_thickness_from_simulation,\n",
    "    gdirs, \n",
    "    input_filesuffix='_random_s1',  # Use the simulation we just did\n",
    "    concat_input_filesuffix='_spinup_historical',  # Concatenate with the historical spinup\n",
    "    output_filesuffix='',  # filesuffix added to the output filename gridded_simulation.nc, if empty input_filesuffix is used\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Let's have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This below is only to open the file again later if needed\n",
    "# with xr.open_dataset(gdir.get_filepath('gridded_simulation', filesuffix='_random_s1')) as ds:\n",
    "#     ds = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_distributed_thickness(ds, title):\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    ds.simulated_thickness.sel(time=2005).plot(ax=ax1, vmax=400);\n",
    "    ds.simulated_thickness.sel(time=2050).plot(ax=ax2, vmax=400);\n",
    "    ds.simulated_thickness.sel(time=2100).plot(ax=ax3, vmax=400);\n",
    "    ax1.axis('equal'); ax2.axis('equal'); f.suptitle(title, fontsize=20);\n",
    "    plt.tight_layout();\n",
    "\n",
    "plot_distributed_thickness(ds[0], 'Aletsch')\n",
    "# plot_distributed_thickness(ds[1], 'Fieschergletscher')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Note: the simulation before the RGI date cannot be trusted - it is the result of the dynamical spinup. Furthermore, if the area is larger than the RGI glacier, the redistribution algorithm will put all mass in the glacier mask, which is not what we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_area(ds, gdir, title):\n",
    "    area = (ds.simulated_thickness > 0).sum(dim=['x', 'y']) * gdir.grid.dx**2 * 1e-6\n",
    "    area.plot(label='Distributed area');\n",
    "    plt.hlines(gdir.rgi_area_km2, gdir.rgi_date, 2100, color='C3', linestyles='--', label='RGI Area');\n",
    "    plt.legend(loc='lower left'); plt.ylabel('Area [km2]'); plt.title(title, fontsize=20); plt.show();\n",
    "\n",
    "\n",
    "plot_area(ds[0], gdirs[0], 'Aletsch')\n",
    "# plot_area(ds[1], gdirs[1], 'Fieschergletscher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Volume however is conserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_volume(ds, gdir, title):\n",
    "    vol = ds.simulated_thickness.sum(dim=['x', 'y']) * gdir.grid.dx**2 * 1e-9\n",
    "    vol.plot(label='Distributed volume'); plt.ylabel('Distributed volume [km3]');\n",
    "    plt.title(title, fontsize=20); plt.show();\n",
    "\n",
    "\n",
    "plot_volume(ds[0], gdirs[0], 'Aletsch')\n",
    "# plot_volume(ds[1], gdirs[1], 'Fieschergletscher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Therefore, lets just keep all data after the RGI year only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, (ds_single, gdir) in enumerate(zip(ds, gdirs)):\n",
    "    ds[i] = ds_single.sel(time=slice(gdir.rgi_date, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Animation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Get a handle on the figure and the axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "thk = ds[0]['simulated_thickness']  # Aletsch\n",
    "# thk = ds[1]['simulated_thickness']  # Fieschergletscher\n",
    "\n",
    "# Plot the initial frame. \n",
    "cax = thk.isel(time=0).plot(ax=ax,\n",
    "    add_colorbar=True,\n",
    "    cmap='viridis',\n",
    "    vmin=0, vmax=thk.max(),\n",
    "    cbar_kwargs={\n",
    "        'extend':'neither'\n",
    "    }\n",
    ")\n",
    "ax.axis('equal')\n",
    "\n",
    "def animate(frame):\n",
    "    ax.set_title(f'Year {int(thk.time[frame])}')\n",
    "    cax.set_array(thk.values[frame, :].flatten())\n",
    "\n",
    "ani_glacier = animation.FuncAnimation(fig, animate, frames=len(thk.time), interval=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(ani_glacier.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write to mp4?\n",
    "# FFwriter = animation.FFMpegWriter(fps=10)\n",
    "# ani2.save('animation.mp4', writer=FFwriter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Finetune the visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "When applying the tools you might see that sometimes the timeseries are \"shaky\", or have sudden changes in area. This comes from a few reasons:\n",
    "- OGGM does not distinguish between ice and snow, i.e. when it snows a lot sometimes OGGM thinks there is a glacier for a couple of years.\n",
    "- the trapezoidal flowlines result in sudden (\"step\") area changes when they melt entirely. \n",
    "- on small glaciers, the changes within one year can be big, and you may want to have more intermediate frames\n",
    "\n",
    "We implement some workarounds for these situations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_smooth = workflow.execute_entity_task(\n",
    "    distribute_2d.distribute_thickness_from_simulation,\n",
    "    gdirs,\n",
    "    input_filesuffix='_random_s1',\n",
    "    concat_input_filesuffix='_spinup_historical', \n",
    "    ys=2003, ye=2100,  # make the output smaller\n",
    "    output_filesuffix='_random_s1_smooth',  # do not overwrite the previous file (optional) \n",
    "    # add_monthly=True,  # more frames! (12 times more - we comment for the demo, but recommend it)\n",
    "    rolling_mean_smoothing=7,  # smooth the area time series\n",
    "    fl_thickness_threshold=1,  # avoid snow patches to be nisclassified\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_area_smoothed(ds_smooth, ds, gdir, title):\n",
    "    area = (ds.simulated_thickness > 0).sum(dim=['x', 'y']) * gdir.grid.dx**2 * 1e-6\n",
    "    area.plot(label='Distributed area (raw)');\n",
    "    area = (ds_smooth.simulated_thickness > 0).sum(dim=['x', 'y']) * gdir.grid.dx**2 * 1e-6\n",
    "    area.plot(label='Distributed area (smooth)');\n",
    "    plt.legend(loc='lower left'); plt.ylabel('Area [km2]');\n",
    "    plt.title(title, fontsize=20); plt.show();\n",
    "\n",
    "\n",
    "plot_area_smoothed(ds_smooth[0], ds[0], gdirs[0], 'Aletsch')\n",
    "# plot_area_smoothed(ds_smooth[1], ds[1], gdirs[1], 'Fieschergletscher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a handle on the figure and the axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "thk = ds_smooth[0]['simulated_thickness']  # Aletsch\n",
    "# thk = ds_smooth[1]['simulated_thickness']  # Fieschergletscher\n",
    "\n",
    "# Plot the initial frame. \n",
    "cax = thk.isel(time=0).plot(ax=ax,\n",
    "    add_colorbar=True,\n",
    "    cmap='viridis',\n",
    "    vmin=0, vmax=thk.max(),\n",
    "    cbar_kwargs={\n",
    "        'extend':'neither'\n",
    "    }\n",
    ")\n",
    "ax.axis('equal')\n",
    "\n",
    "def animate(frame):\n",
    "    ax.set_title(f'Year {float(thk.time[frame]):.1f}')\n",
    "    cax.set_array(thk.values[frame, :].flatten())\n",
    "\n",
    "ani_glacier = animation.FuncAnimation(fig, animate, frames=len(thk.time), interval=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "HTML(ani_glacier.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write to mp4?\n",
    "# FFwriter = animation.FFMpegWriter(fps=120)\n",
    "# ani2.save('animation_smooth.mp4', writer=FFwriter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Merge redistributed thickness from multiple glaciers\n",
    "\n",
    "If you're working in a region with multiple glaciers, displaying the evolution of all glaciers simultaneously can be convenient. To facilitate this, we offer a tool that merges the simulated distributed thicknesses of multiple glaciers.\n",
    "\n",
    "This process can be very memory-intensive. To prevent memory overflow issues, we, by default, merge the data for each year into a separate file. If you have sufficient resources, you can set `save_as_multiple_files=False` to compile the data into a single file at the end. However, with `xarray.open_mfdataset`, you have the capability to seamlessly open and work with these multiple files as if they were one.\n",
    "\n",
    "For further explanation on merging `gridded_data`, please consult the tutorial [Ingest gridded products such as ice velocity into OGGM](../tutorials/ingest_gridded_data_on_flowlines.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulation_filesuffix = '_random_s1_smooth'  # saved in variable for later opening of the files\n",
    "distribute_2d.merge_simulated_thickness(\n",
    "    gdirs,  # the gdirs we want to merge\n",
    "    simulation_filesuffix=simulation_filesuffix,  # the name of the simulation\n",
    "    years_to_merge=np.arange(2005, 2101, 5),  # for demonstration I only pick some years, if this is None all years are merged\n",
    "    add_topography=True,  # if you do not need topogrpahy setting this to False will decrease computing time\n",
    "    preserve_totals=True,  # preserve individual glacier volumes during merging\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# by default the resulting files are saved in cfg.PATHS['working_dir']\n",
    "# with names gridded_simulation_merged{simulation_filesuffix}{yr}.\n",
    "# To open all at once we first get all corresponding files\n",
    "files_to_open = glob.glob(\n",
    "    os.path.join(\n",
    "        cfg.PATHS['working_dir'],  # the default output_folder\n",
    "        f'gridded_simulation_merged{simulation_filesuffix}*.nc',  # with the * we open all files which matches the pattern\n",
    "    )\n",
    ")\n",
    "\n",
    "files_to_open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "You will notice that there is a file for each year, as well as one file with the suffix `_topo_data`. As the name suggests, this file contains the topography and gridded-outline information of the merged glaciers, which could be useful for visualizations.\n",
    "\n",
    "Now we open all files in one dataset with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with xr.open_mfdataset(files_to_open) as ds_merged:\n",
    "    ds_merged = ds_merged.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Now we can look at the result with a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_distributed_thickness(ds_merged, 'Aletsch and Fieschergletscher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Alternatively, you can create an animation using the merged data, displaying a value every 5 years, as specified above with `years_to_merge`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a handle on the figure and the axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "thk = ds_merged['simulated_thickness']\n",
    "\n",
    "# Plot the initial frame. \n",
    "cax = thk.isel(time=0).plot(ax=ax,\n",
    "    add_colorbar=True,\n",
    "    cmap='viridis',\n",
    "    vmin=0, vmax=thk.max(),\n",
    "    cbar_kwargs={\n",
    "        'extend':'neither'\n",
    "    }\n",
    ")\n",
    "ax.axis('equal')\n",
    "\n",
    "def animate(frame):\n",
    "    ax.set_title(f'Year {float(thk.time[frame]):.1f}')\n",
    "    cax.set_array(thk.values[frame, :].flatten())\n",
    "\n",
    "ani_glacier = animation.FuncAnimation(fig, animate, frames=len(thk.time), interval=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "HTML(ani_glacier.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "For visualization purposes, the merged dataset also includes the topography of the entire region, encompassing the glacier surfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap=salem.get_cmap('topo')\n",
    "ds_merged.topo.plot(cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "Or the estimated bedrock topography, without ice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_merged.bedrock.plot(cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## Nice 3D videos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "We are working on a tool to make even nicer videos like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"../../img/mittelbergferner.mp4\", embed=True, width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "The WIP tool is available here: https://github.com/OGGM/oggm-3dviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
